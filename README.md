# ğŸ“„ Multilingual PDF RAG Assistant (FastAPI + Multilingual + OCR)

A **Retrieval-Augmented Generation (RAG)** based intelligent document assistant that allows users to upload PDF documents and ask context-aware questions in **English and Hindi**, with **optional audio responses**.

---

## ğŸŒ Project Overview

This project is designed to work with different types of documents, including:

- ğŸ“Š Structured documents (Bank Statements)
- ğŸ§¾ Semi-structured documents (Invoices)
- ğŸ“œ Unstructured documents (Agreements, Letters)

The system extracts text from PDFs, retrieves relevant context using vector embeddings, and generates **accurate, grounded answers** using a **local LLM (Mistral via Ollama)**.

---

## â­ Features

### ğŸ”¹ 1. PDF Upload & Processing
- Upload PDF documents via Streamlit UI
- Native text extraction
- Table extraction
- OCR fallback for scanned PDFs

---

### ğŸ”¹ 2. Intelligent Chunking & Embeddings
- Structure-aware chunking
- Vector embeddings using Sentence Transformers
- Persistent storage using ChromaDB

---

### ğŸ”¹ 3. Context-Aware Question Answering (RAG)
Ask natural language questions such as:
- â€œWhat is the account holder name?â€
- â€œWhat is the total balance?â€
- â€œIs nominee information mentioned?â€

Answers are:
- Strictly based on document content
- Hallucination-controlled
- Short and precise

---

### ğŸ”¹ 4. Multilingual Support
- English question & answers
- Hindi question & answers
- Language-specific strict prompting

---

### ğŸ”¹ 5. Optional Audio Responses
- Text-to-Speech output
- MP3 audio generated dynamically

---

## ğŸ›  Tech Stack

### Backend
- FastAPI
- ChromaDB
- Sentence Transformers
- pdfplumber
- pytesseract (OCR)
- Ollama (Mistral LLM)

### Frontend
- Streamlit

### AI Models
- all-MiniLM-L6-v2 (Embeddings)
- Mistral (LLM via Ollama)
- gTTS (Text-to-Speech)
- Helsinki-NLP Translation Models
  
---
## ğŸ§  System Architecture

The system follows a Retrieval-Augmented Generation (RAG) pipeline where
relevant document context is retrieved using vector similarity before generating
answers using a local large language model.

User  
â¬‡  
Streamlit Frontend  
â¬‡  
FastAPI Backend  
â¬‡  
PDF Processing (Native Text + OCR)  
â¬‡  
Text Chunking  
â¬‡  
Embedding (Sentence Transformers)  
â¬‡  
ChromaDB Vector Store  
â¬‡  
LLM (Mistral via Ollama)  
â¬‡  
Response Generation + Optional TTS  

---


## â–¶ï¸ How to Run the Project

1. Create and activate virtual environment  
2. Install dependencies using `requirements.txt`  
3. Start Ollama with Mistral model  
4. Run FastAPI backend  
5. Launch Streamlit frontend  

Refer to the commands in the repository for local execution.

---

## ğŸ“¸ Screenshots

### Upload Interface

![Upload](assets/upload.png)
### Question Answering (English)

![English QA](assets/chat_en_audio.png)

---

ğŸ”Š Audio responses are generated dynamically at runtime and are not stored in the repository.

### Question Answering (Hindi)

![Hindi QA](assets/chat_hi_audio.png)


---


## ğŸ§ª Example Use Cases

- Extract account details from bank statements
- Verify invoice totals and tax values
- Understand clauses in rent agreements
- Ask document questions in Hindi or English

---

| Feature                  | Implemented |
| ------------------------ | ----------- |
| PDF Upload               | âœ…           |
| OCR Support              | âœ…           |
| Intelligent Chunking     | âœ…           |
| Semantic Search (RAG)    | âœ…           |
| Multilingual Support     | âœ…           |
| Strict Context Answering | âœ…           |
| Audio Response           | âœ…           |
| Persistent Vector DB     | âœ…           |
| Local LLM Integration    | âœ…           |



