# ğŸ“„ Multilingual PDF RAG Assistant

## ğŸš€ Project Overview

This project is a Retrieval-Augmented Generation (RAG) system that enables users to upload PDF documents and ask questions about them in English or Hindi.

The assistant supports:

- ğŸ“Š Structured Data (Bank Statements)
- ğŸ§¾ Semi-Structured Data (Invoices)
- ğŸ“œ Unstructured Data (Rent Agreements)

It extracts information, retrieves relevant context using vector embeddings, and generates accurate responses using a local LLM (Mistral via Ollama).

---

## â­ Key Highlights

- Strict hallucination-free document question answering
- Works completely offline using local LLM (Ollama + Mistral)
- Handles structured, semi-structured, and unstructured PDFs
- Finance-safe and legal-safe answer generation
- Beginner-friendly yet production-ready RAG architecture

---

## ğŸ¯ Problem Statement

Organizations deal with multiple document formats such as invoices, legal agreements, and financial statements. Extracting information manually is time-consuming and error-prone.

This project builds a smart assistant that:

- Understands structured and unstructured PDFs
- Performs contextual question answering
- Supports multilingual interaction
- Provides optional voice output
- Answers are generated strictly from document content
- If information is missing, the assistant clearly responds with â€œNot mentioned in the documentâ€
- Prevents logical guessing and numerical hallucinations in financial documents

---

## ğŸ§  System Architecture

The system follows a Retrieval-Augmented Generation (RAG) pipeline where
relevant document context is retrieved using vector similarity before generating
answers using a local large language model.

User  
â¬‡  
Streamlit Frontend  
â¬‡  
FastAPI Backend  
â¬‡  
PDF Processing (Native Text + OCR)  
â¬‡  
Text Chunking  
â¬‡  
Embedding (Sentence Transformers)  
â¬‡  
ChromaDB Vector Store  
â¬‡  
LLM (Mistral via Ollama)  
â¬‡  
Response Generation + Optional TTS  

---

## âœ¨ Features

- ğŸ“‚ PDF Upload
- ğŸ” Native Text Extraction + OCR fallback
- ğŸ§© Intelligent Chunking
- ğŸ” Semantic Search using ChromaDB
- ğŸ¤– Local LLM (Mistral)
- ğŸŒ English & Hindi Support
- ğŸ”Š Text-to-Speech Output
- ğŸ§  Context-Grounded Prompting (Hallucination Reduction)
- ğŸ’¬ Interactive Streamlit UI
- Reduces human error in financial and legal document analysis
- Improves accessibility with multilingual and audio responses

---

## ğŸ›  Tech Stack

Backend:
- FastAPI
- ChromaDB
- Sentence Transformers
- pdfplumber
- pytesseract
- Ollama (Mistral)

Frontend:
- Streamlit

AI Models:
- all-MiniLM-L6-v2 (Embeddings)
- Mistral (LLM via Ollama)
- Helsinki-NLP Translation Models
- gTTS (Text-to-Speech)

---

## â–¶ï¸ How to Run the Project

1. Create and activate virtual environment  
2. Install dependencies using `requirements.txt`  
3. Start Ollama with Mistral model  
4. Run FastAPI backend  
5. Launch Streamlit frontend  

Refer to the commands in the repository for local execution.

---

## ğŸ“¸ Screenshots

### Upload Interface

![Upload](assets/upload.png)

### Question Answering (English)

![English QA](assets/chat_en_audio.png)

---

### Question Answering (Hindi)

![Hindi QA](assets/chat_hi_audio.png)


---

## ğŸ§ª Example Use Cases

- Extract account details from bank statements
- Verify invoice totals and tax values
- Understand clauses in rent agreements
- Ask document questions in Hindi or English





